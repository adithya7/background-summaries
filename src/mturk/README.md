# MTurk setup

## Best-worst Scaling (BWS)

We ask turkers to compare human-written summaries, and those generated by `flan-t5-xl` and `gpt-3.5-turbo`. Three annotators rate best (most helpful) and worst (least helpful) summaries among the three. In our work, we use a random sample of 1,000 news updates from the test set.

```bash
# prepare JSON-L files containing input data for MTurk
bash bash_scripts/mturk/preprocess.sh
```

See [data](data) for the MTurk template.

## BUS--Human

We ask annotators to generate five background questions for each of the 1,000 news updates. For each of these tuples of update and questions, we pair it with one of the associated background summaries and ask annotators to attempt to answer all five questions using only the information from the background summary (or write _none_ if the summary does not contain the answer).

```bash
# prepare JSON-L files for question generation on MTurk
bash bash_scripts/mturk/preprocess_q.sh
```

[src/mturk/question_data](src/mturk/question_data) and [src/mturk/answer_data](src/mturk/answer_data) contain the MTurk template for question and answer-generation tasks respectively.
