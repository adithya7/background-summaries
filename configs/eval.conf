base {
    # TODO: update model_name_or_path
    # huggingface dataset loading script
    # TODO: specify full path to the script
    dataset_path = data/background_summ.py
    hf_tokenized_dataset_path = outputs/hf_tokenized
    output_path = outputs/hf
    log_path = logs/hf
}

t5-default = ${base}{
    gen_kwargs = {
        do_sample = false
        early_stopping = false
        length_penalty = 2.0
        max_new_tokens = 400
        no_repeat_ngram_size = 3
        num_beams = 4
    }
    eval = true
    split = validation
    batch_size = 16
}

flan-t5-xl = ${t5-default}{
    tokenizer = google/flan-t5-xl
    model_name_or_path = ${base.output_path}/flan-t5-xl
}

flan-t5-xl-ift = ${t5-default}{
    tokenizer = google/flan-t5-xl
    model_name_or_path = ${base.output_path}/flan-t5-xl-ift
}

flan-t5-xl-ift-ents = ${t5-default}{
    tokenizer = google/flan-t5-xl
    model_name_or_path = ${base.output_path}/flan-t5-xl-ift-ents
}

long-t5-tglobal-xl = ${t5-default}{
    tokenizer = google/long-t5-tglobal-xl
    model_name_or_path = ${base.output_path}/long-t5-tglobal-xl
    batch_size = 8
    bf16 = true
    gen_kwargs = {
        do_sample = false
        early_stopping = false
        length_penalty = 2.0
        max_new_tokens = 400
        no_repeat_ngram_size = 3
        num_beams = 4
    }
}
